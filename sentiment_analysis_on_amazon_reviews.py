# -*- coding: utf-8 -*-
"""Sentiment Analysis on Amazon Reviews.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lfXmDXRvMFHndING4GrULlvG-fSRdIaw

**Sentiment analysis on amazon Reviews**

Sentiment analysis is the process of classifying whether a block of text is positive, negative, or, neutral. The goal which Sentiment analysis tries to gain is to be analyzed peopleâ€™s opinions in a way that can help businesses expand. It focuses not only on polarity (positive, negative & neutral) but also on emotions (happy, sad, angry, etc.). It uses various Natural Language Processing algorithms such as Rule-based, Automatic, and Hybrid.
"""

import warnings
warnings.filterwarnings('ignore')
import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
import matplotlib.pyplot as plt
from wordcloud import WordCloud

"""Amazon gives a platform to small businesses and companies with modest resources to grow larger. And Because of its popularity, people actually spend time and write detailed reviews, about the brand and the product. So, by analyzing that data we can tell companies a lot about their products and also the ways to enhance the quality of the product. But that large amount of data can not be analyzed by a person.

**Steps to be followed**

1.Importing Libraries and Datasets

2.Preprocessing and cleaning the reviews 

3.Analysis of the Dataset

4.Converting text into Vectors

5.Model training, Evaluation, and Prediction
"""

import nltk
nltk.download('punkt')
nltk.download('stopwords')
from nltk.corpus import stopwords

path="/content/AmazonReview.csv"
data = pd.read_csv('AmazonReview.csv')
data.head()

data.info()

data.dropna(inplace=True)

#1,2,3->negative(i.e 0)
data.loc[data['Sentiment']<=3,'Sentiment'] = 0

#4,5->positive(i.e 1)
data.loc[data['Sentiment']>3,'Sentiment'] = 1

stp_words=stopwords.words('english')
def clean_review(review):
  cleanreview=" ".join(word for word in review.
					split() if word not in stp_words)
  return cleanreview

data['Review']=data['Review'].apply(clean_review)

data.head()

data['Sentiment'].value_counts()

data['Sentiment'].value_counts()

consolidated=' '.join(word for word in data['Review'][data['Sentiment']==0].astype(str))
wordCloud=WordCloud(width=1600,height=800,random_state=21,max_font_size=110)
plt.figure(figsize=(15,10))
plt.imshow(wordCloud.generate(consolidated),interpolation='bilinear')
plt.axis('off')
plt.show()

cv = TfidfVectorizer(max_features=2500)
X = cv.fit_transform(data['Review'] ).toarray()

from sklearn.model_selection import train_test_split
x_train ,x_test,y_train,y_test=train_test_split(X,data['Sentiment'],
												test_size=0.25 ,
												random_state=42)

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score
model=LogisticRegression()

#Model fitting
model.fit(x_train,y_train)

#testing the model
pred=model.predict(x_test)

#model accuracy
print(accuracy_score(y_test,pred))

from sklearn.metrics import confusion_matrix
cm = confusion_matrix(y_test,pred)

cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,
											display_labels = [False, True])

cm_display.plot()
plt.show()